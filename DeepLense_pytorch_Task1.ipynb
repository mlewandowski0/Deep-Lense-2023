{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Setup Dataset"
      ],
      "metadata": {
        "id": "oYwZfmJJGFhF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch \n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision.models import resnet50, resnet152, resnet18\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from torchvision.models.densenet import DenseNet\n",
        "from torchsummary import summary\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets.folder import DatasetFolder\n",
        "import torchvision\n",
        "import os\n",
        "import gc\n",
        "import time\n",
        "import copy\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from collections import defaultdict, Counter\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchsummary import summary\n",
        "import torch.optim as pt_optim\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim.lr_scheduler as pt_lr_scheduler\n",
        "from torchvision.datasets.folder import DatasetFolder"
      ],
      "metadata": {
        "id": "8gxSK6KnHzlk"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "try:\n",
        "  import google.colab\n",
        "  COLAB_ENV = True\n",
        "except:\n",
        "  COLAB_ENV = False\n",
        "\n",
        "\n",
        "if COLAB_ENV:\n",
        "  data_filepath = \"/\" + os.path.join(\"content\",\"drive\",\"MyDrive\",\"datasets\", \"ML4SCI_GSOC23\")\n",
        "  SAVE_MODEL_PATH = os.path.join(data_filepath, \"gravitational-lensing\", \"Task1\", \"models\")\n",
        "  os.makedirs(SAVE_MODEL_PATH, exist_ok=True)\n",
        "  os.listdir(SAVE_MODEL_PATH)\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "else:\n",
        "  data_filepath = \"data\"\n",
        "     "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fOfBM_ThGFtm",
        "outputId": "5b9c1d3a-6474-4a33-c539-d0acedc38aa4"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/datasets/ML4SCI_GSOC23/gravitational-lensing/Task1/dataset.zip .\n",
        "!unzip -q dataset.zip"
      ],
      "metadata": {
        "id": "GbKEjv1EGg1K"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def getFilenamesFullPath(path):\n",
        "  no_path = os.path.join(*path)\n",
        "  no = os.listdir(no_path)\n",
        "  return sorted([os.path.join(no_path, v) for v in no])\n",
        "\n",
        "dataset_filepath_train = os.path.join(\"dataset\", \"train\")\n",
        "dataset_filepath_val = os.path.join(\"dataset\", \"val\")\n",
        "\n",
        "print(os.listdir(dataset_filepath_train))\n",
        "\n",
        "no = getFilenamesFullPath([\"dataset\", \"train\", \"no\"])\n",
        "vort = getFilenamesFullPath([\"dataset\", \"train\", \"vort\"])\n",
        "sphere = getFilenamesFullPath([\"dataset\", \"train\", \"sphere\"])\n",
        "\n",
        "print(f\"size of no class : {len(no)}\")\n",
        "print(f\"size of vort class : {len(vort)}\")\n",
        "print(f\"size of sphere class : {len(sphere)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oMTr8Z3iG1LR",
        "outputId": "554c608b-aa90-4c16-ea27-6d952e62acb7"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['no', 'vort', 'sphere', '.DS_Store']\n",
            "size of no class : 10000\n",
            "size of vort class : 10000\n",
            "size of sphere class : 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Device Used : {device}\")\n",
        "\n",
        "mean = 0.485\n",
        "std = 0.229\n",
        "\n",
        "mean = 0.06169275318411914\n",
        "std = 0.1172684106873827\n",
        "batch_size = 64\n",
        "\n",
        "_transforms = transforms.Compose([\n",
        "    torchvision.transforms.Normalize((mean), (std))\n",
        "])\n",
        "\n",
        "def load_npy(path : str) -> torch.Tensor:\n",
        "    # load the image\n",
        "    img = torch.from_numpy(np.load(path))\n",
        "\n",
        "    # preprocess it     \n",
        "    return _transforms(img)\n",
        "\n",
        "train_ds = DatasetFolder(dataset_filepath_train, extensions=[\".npy\"], loader=load_npy)\n",
        "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "test_ds = DatasetFolder(dataset_filepath_val, extensions=[\".npy\"], loader=load_npy)\n",
        "test_dl = DataLoader(test_ds, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eab_fBZGHxRD",
        "outputId": "83848a8e-a478-4316-e138-624c80cba8a3"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device Used : cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pytorch utils"
      ],
      "metadata": {
        "id": "2mQgxS3eSo8_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, valid_dataset, valid_dataset_len):\n",
        "    since = time.time()\n",
        "\n",
        "    # Each epoch has a training and validation phase\n",
        "    model.eval()   # Set model to evaluate mode\n",
        "\n",
        "    running_loss = 0.0\n",
        "    running_corrects = 0\n",
        "    y = torch.Tensor()\n",
        "    pred_y = torch.Tensor()\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Iterate over data.\n",
        "    for inputs, labels in tqdm(valid_dataset):\n",
        "        inputs = torch.cat([inputs,inputs,inputs],1)\n",
        "        inputs = inputs.to(device).float()\n",
        "        labels = labels.to(device)\n",
        "        labels = labels.long()\n",
        "        y = torch.cat([y, labels.cpu()])\n",
        "        \n",
        "        # forward\n",
        "        # track history if only in train\n",
        "        with torch.set_grad_enabled(False):\n",
        "            outputs = model(inputs)\n",
        "            probs, preds = torch.max(outputs, 1)\n",
        "            \n",
        "            #print(outputs.shape)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            pred_y = torch.cat([pred_y, outputs.cpu()])\n",
        "\n",
        "            # statistics\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "    epoch_loss = running_loss / valid_dataset_len\n",
        "    epoch_acc = running_corrects.double() / valid_dataset_len\n",
        "    AUC_ROC = roc_auc_score(y.detach().numpy(), F.softmax(pred_y, dim=1).detach().numpy(), multi_class=\"ovr\")  \n",
        "\n",
        "    \n",
        "    time_elapsed = time.time() - since\n",
        "    print(f'VALIDATION : Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f} AUC ROC : {AUC_ROC:.4f} Time taken : {round(time.time() - since, 2)}')"
      ],
      "metadata": {
        "id": "Pqla0ddjSxJY"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def training_epoch(model, optimizer, scheduler, \n",
        "                   train_dataloader, train_dataset_size,\n",
        "                   valid_dataloader, valid_dataset_size, \n",
        "                   num_epochs=25, update_every=5,\n",
        "                   clean_every = 10):\n",
        "    since = time.time()\n",
        "\n",
        "    returnDict = {\"trainingLoss\" : [], \"trainingAccuracy\" : [], \"epochs\" : [], \"trainingAUC\" : []}\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "    \n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
        "        print('-' * 10)\n",
        "        returnDict[\"epochs\"].append(epoch)\n",
        "\n",
        "        since2 = time.time()\n",
        "        model.train()  # Set model to training mode\n",
        "\n",
        "        running_loss = 0.0\n",
        "        running_corrects = 0\n",
        "        y = torch.Tensor()\n",
        "        pred_y = torch.Tensor()\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "        i = 0\n",
        "        samples_so_far = 0\n",
        "        # Iterate over data.\n",
        "        progress_bar = tqdm(train_dataloader)\n",
        "        for inputs, labels in progress_bar:\n",
        "            i += 1\n",
        "            samples_so_far += inputs.shape[0]\n",
        "            inputs = torch.cat([inputs,inputs,inputs],1)\n",
        "            inputs = inputs.to(device).float()\n",
        "            labels = labels.to(device)\n",
        "            labels = labels.long()\n",
        "\n",
        "            y = torch.cat([y, labels.cpu()])\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward\n",
        "            # track history if only in train\n",
        "            with torch.set_grad_enabled(True):\n",
        "                outputs = model(inputs).softmax(dim=1)\n",
        "                probs, preds = torch.max(outputs, 1)\n",
        "                loss = criterion(outputs, labels)\n",
        "                pred_y = torch.cat([pred_y, outputs.cpu()])\n",
        "\n",
        "                # backward + optimize only if in training phase\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "            # statistics\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            if i % update_every == 0:\n",
        "                rl_avg = running_loss / samples_so_far\n",
        "                acc_avg = running_corrects / samples_so_far\n",
        "                AUC_ROC = roc_auc_score(y.detach().numpy(), F.softmax(pred_y, dim=1).detach().numpy(), multi_class=\"ovr\")  \n",
        "\n",
        "                progress_bar.set_description(f\"loss = {rl_avg}, accuracy : {acc_avg}, AUC ROC {AUC_ROC}\")\n",
        "            \n",
        "            if clean_every != -1 and i % clean_every == 0:\n",
        "                gc.collect()\n",
        "            scheduler.step()\n",
        "            \n",
        "        epoch_loss = running_loss / train_dataset_size\n",
        "        epoch_acc = running_corrects.double() / train_dataset_size\n",
        "        AUC_ROC = roc_auc_score(y.detach().numpy(), F.softmax(pred_y, dim=1).detach().numpy(), multi_class=\"ovr\")  \n",
        "\n",
        "        returnDict[\"trainingLoss\"].append(epoch_loss)\n",
        "        returnDict[\"trainingAccuracy\"].append(epoch_acc.cpu().item())\n",
        "        returnDict[\"trainingAUC\"].append(AUC_ROC)\n",
        "\n",
        "        print(f'TRAINING ; Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f} AUC ROC : {AUC_ROC:.4f} Time taken : {round(time.time() - since2, 2)}')\n",
        "        evaluate_model(model, valid_dataloader, valid_dataset_size)\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
        "\n",
        "    # load best model weights\n",
        "    returnDict[\"best_model\"] = model\n",
        "    return returnDict"
      ],
      "metadata": {
        "id": "SQ7sFnEFSz9B"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plotResults(results):\n",
        "    plt.figure(figsize=(16,12))\n",
        "    plt.subplot(3,1, 1)\n",
        "    plt.plot(results['epochs'], results['trainingLoss'], label=\"training Loss\")\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(3,1, 2)\n",
        "    plt.plot(results['epochs'], results['trainingAccuracy'], label=\"training Accuracy\")\n",
        "    plt.legend()\n",
        "  \n",
        "  \n",
        "    plt.subplot(3,1, 3)\n",
        "    plt.plot(results['epochs'], results['trainingAUC'], label=\"training ROC\")\n",
        "    plt.legend()\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "NI_4fxMMS10S"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def doExperiment(model_ft, epochs=10, learning_rate=1e-3, plot=True, _summary=True, input_size=(3,32,32)):\n",
        "  global train_dl, train_ds, val_dl, val_ds\n",
        "  if _summary:\n",
        "    print(summary(model_ft, input_size=input_size, device=\"cpu\"))\n",
        "  \n",
        "  model_ft = model_ft.to(device)\n",
        "  optim = pt_optim.Adam(model_ft.parameters(), lr=learning_rate, weight_decay=3e-5)\n",
        "  lr_sched = pt_lr_scheduler.CyclicLR(optim, learning_rate, 5 * learning_rate, step_size_up=round(len(train_ds) / batch_size), cycle_momentum=False)\n",
        "\n",
        "  dats = training_epoch(model_ft, optim, lr_sched, \n",
        "                        train_dl,  len(train_ds) , \n",
        "                        val_dl, len(val_ds),\n",
        "                        num_epochs=epochs)\n",
        "  \n",
        "  if plot:\n",
        "    plotResults(dats)\n",
        "  return dats"
      ],
      "metadata": {
        "id": "pwylbphzS2Ti"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train RESNET"
      ],
      "metadata": {
        "id": "1dnE5xwpSwF4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = resnet18(True)\n",
        "model.fc = torch.nn.Linear(512,3)\n",
        "doExperiment(model, learning_rate=3e-4, input_size=(3, 125, 125))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hdPvP6cBTyqy",
        "outputId": "78b6a070-f55a-4028-9879-942a367936f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:135: UserWarning: Using 'weights' as positional parameter(s) is deprecated since 0.13 and may be removed in the future. Please use keyword parameter(s) instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 63, 63]           9,408\n",
            "       BatchNorm2d-2           [-1, 64, 63, 63]             128\n",
            "              ReLU-3           [-1, 64, 63, 63]               0\n",
            "         MaxPool2d-4           [-1, 64, 32, 32]               0\n",
            "            Conv2d-5           [-1, 64, 32, 32]          36,864\n",
            "       BatchNorm2d-6           [-1, 64, 32, 32]             128\n",
            "              ReLU-7           [-1, 64, 32, 32]               0\n",
            "            Conv2d-8           [-1, 64, 32, 32]          36,864\n",
            "       BatchNorm2d-9           [-1, 64, 32, 32]             128\n",
            "             ReLU-10           [-1, 64, 32, 32]               0\n",
            "       BasicBlock-11           [-1, 64, 32, 32]               0\n",
            "           Conv2d-12           [-1, 64, 32, 32]          36,864\n",
            "      BatchNorm2d-13           [-1, 64, 32, 32]             128\n",
            "             ReLU-14           [-1, 64, 32, 32]               0\n",
            "           Conv2d-15           [-1, 64, 32, 32]          36,864\n",
            "      BatchNorm2d-16           [-1, 64, 32, 32]             128\n",
            "             ReLU-17           [-1, 64, 32, 32]               0\n",
            "       BasicBlock-18           [-1, 64, 32, 32]               0\n",
            "           Conv2d-19          [-1, 128, 16, 16]          73,728\n",
            "      BatchNorm2d-20          [-1, 128, 16, 16]             256\n",
            "             ReLU-21          [-1, 128, 16, 16]               0\n",
            "           Conv2d-22          [-1, 128, 16, 16]         147,456\n",
            "      BatchNorm2d-23          [-1, 128, 16, 16]             256\n",
            "           Conv2d-24          [-1, 128, 16, 16]           8,192\n",
            "      BatchNorm2d-25          [-1, 128, 16, 16]             256\n",
            "             ReLU-26          [-1, 128, 16, 16]               0\n",
            "       BasicBlock-27          [-1, 128, 16, 16]               0\n",
            "           Conv2d-28          [-1, 128, 16, 16]         147,456\n",
            "      BatchNorm2d-29          [-1, 128, 16, 16]             256\n",
            "             ReLU-30          [-1, 128, 16, 16]               0\n",
            "           Conv2d-31          [-1, 128, 16, 16]         147,456\n",
            "      BatchNorm2d-32          [-1, 128, 16, 16]             256\n",
            "             ReLU-33          [-1, 128, 16, 16]               0\n",
            "       BasicBlock-34          [-1, 128, 16, 16]               0\n",
            "           Conv2d-35            [-1, 256, 8, 8]         294,912\n",
            "      BatchNorm2d-36            [-1, 256, 8, 8]             512\n",
            "             ReLU-37            [-1, 256, 8, 8]               0\n",
            "           Conv2d-38            [-1, 256, 8, 8]         589,824\n",
            "      BatchNorm2d-39            [-1, 256, 8, 8]             512\n",
            "           Conv2d-40            [-1, 256, 8, 8]          32,768\n",
            "      BatchNorm2d-41            [-1, 256, 8, 8]             512\n",
            "             ReLU-42            [-1, 256, 8, 8]               0\n",
            "       BasicBlock-43            [-1, 256, 8, 8]               0\n",
            "           Conv2d-44            [-1, 256, 8, 8]         589,824\n",
            "      BatchNorm2d-45            [-1, 256, 8, 8]             512\n",
            "             ReLU-46            [-1, 256, 8, 8]               0\n",
            "           Conv2d-47            [-1, 256, 8, 8]         589,824\n",
            "      BatchNorm2d-48            [-1, 256, 8, 8]             512\n",
            "             ReLU-49            [-1, 256, 8, 8]               0\n",
            "       BasicBlock-50            [-1, 256, 8, 8]               0\n",
            "           Conv2d-51            [-1, 512, 4, 4]       1,179,648\n",
            "      BatchNorm2d-52            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-53            [-1, 512, 4, 4]               0\n",
            "           Conv2d-54            [-1, 512, 4, 4]       2,359,296\n",
            "      BatchNorm2d-55            [-1, 512, 4, 4]           1,024\n",
            "           Conv2d-56            [-1, 512, 4, 4]         131,072\n",
            "      BatchNorm2d-57            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-58            [-1, 512, 4, 4]               0\n",
            "       BasicBlock-59            [-1, 512, 4, 4]               0\n",
            "           Conv2d-60            [-1, 512, 4, 4]       2,359,296\n",
            "      BatchNorm2d-61            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-62            [-1, 512, 4, 4]               0\n",
            "           Conv2d-63            [-1, 512, 4, 4]       2,359,296\n",
            "      BatchNorm2d-64            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-65            [-1, 512, 4, 4]               0\n",
            "       BasicBlock-66            [-1, 512, 4, 4]               0\n",
            "AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n",
            "           Linear-68                    [-1, 3]           1,539\n",
            "================================================================\n",
            "Total params: 11,178,051\n",
            "Trainable params: 11,178,051\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.18\n",
            "Forward/backward pass size (MB): 20.32\n",
            "Params size (MB): 42.64\n",
            "Estimated Total Size (MB): 63.14\n",
            "----------------------------------------------------------------\n",
            "None\n",
            "Epoch 0/9\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss = 1.1327543258666992, accuracy : 0.32901784777641296, AUC ROC 0.49417781018402734:   8%|▊         | 36/469 [00:09<01:48,  3.98it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 966
        },
        "id": "9wTSfrmJFTwD",
        "outputId": "67d8f6c0-d9dd-4423-9d3d-ee5ec08318af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:135: UserWarning: Using 'weights' as positional parameter(s) is deprecated since 0.13 and may be removed in the future. Please use keyword parameter(s) instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tesla T4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 469/469 [01:34<00:00,  4.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc : 0.33623334765434265, test_acc : 0.33506667613983154\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 469/469 [01:34<00:00,  4.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc : 0.3418999910354614, test_acc : 0.3442666530609131\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 469/469 [01:34<00:00,  4.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc : 0.39373332262039185, test_acc : 0.5250666737556458\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 469/469 [01:33<00:00,  5.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc : 0.6227999925613403, test_acc : 0.7385333180427551\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 469/469 [01:33<00:00,  5.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc : 0.7738333344459534, test_acc : 0.7919999957084656\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 469/469 [01:34<00:00,  4.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc : 0.8273000121116638, test_acc : 0.8390666842460632\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 469/469 [01:34<00:00,  4.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc : 0.850433349609375, test_acc : 0.8405333161354065\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 469/469 [01:34<00:00,  4.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc : 0.8611000180244446, test_acc : 0.8518666625022888\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 469/469 [01:34<00:00,  4.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc : 0.8726666569709778, test_acc : 0.8549333214759827\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 469/469 [01:34<00:00,  4.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc : 0.8839666843414307, test_acc : 0.867733359336853\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 469/469 [01:33<00:00,  5.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc : 0.8889333605766296, test_acc : 0.8842666745185852\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 469/469 [01:33<00:00,  4.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc : 0.8949999809265137, test_acc : 0.8829333186149597\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 469/469 [01:34<00:00,  4.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc : 0.8955000042915344, test_acc : 0.878933310508728\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 469/469 [01:36<00:00,  4.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc : 0.9022666811943054, test_acc : 0.8848000168800354\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  5%|▌         | 25/469 [00:04<01:19,  5.58it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-d44865351564>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mzero_grad\u001b[0;34m(self, set_to_none)\u001b[0m\n\u001b[1;32m    277\u001b[0m                                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mforeach\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_sparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m                                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m                             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m                                 \u001b[0mper_device_and_dtype_grads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "HUB_URL = \"SharanSMenon/swin-transformer-hub:main\"\n",
        "MODEL_NAME = \"swin_tiny_patch4_window7_224\"\n",
        "## check hubconf for more models.\n",
        "#model = torch.hub.load(HUB_URL, MODEL_NAME, pretrained=True).cuda()\n",
        "#model.head = torch.nn.Linear(768,3)\n",
        "#model = model.cuda()\n",
        "\n",
        "\n",
        "model = resnet18(True)\n",
        "model.fc = torch.nn.Linear(512,3)\n",
        "\n",
        "\n",
        "\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "N_EPOCHS = 50\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "for i in range(N_EPOCHS):\n",
        "    accuracy = 0\n",
        "    total_loss = 0\n",
        "    for x, y in tqdm(train_dl):\n",
        "        \n",
        "        x = torch.cat([x,x,x],1).float()\n",
        "        x = x.cuda()\n",
        "        y_one_hot = torch.nn.functional.one_hot(y, num_classes=3).float()\n",
        "        y_one_hot = y_one_hot.cuda()\n",
        "\n",
        "        output = model(x).softmax(dim=1)\n",
        "        #print(output)\n",
        "        loss = loss_fn(output, y_one_hot)\n",
        "        label = torch.argmax(output,1).cpu()\n",
        "        \n",
        "        \n",
        "        accuracy += torch.sum(label == y)\n",
        "        \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        total_loss += loss\n",
        "    \n",
        "    test_accuracy = 0    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for x, y in test_dl:\n",
        "            \n",
        "            x = torch.cat([x,x,x],1).float()\n",
        "            x = x.cuda()\n",
        "            y_one_hot = torch.nn.functional.one_hot(y, num_classes=3).float()\n",
        "            y_one_hot = y_one_hot.cuda()\n",
        "\n",
        "            output = model(x)\n",
        "            loss = loss_fn(output, y_one_hot)\n",
        "            label = torch.argmax(output,1).cpu()\n",
        "            test_accuracy += torch.sum(label == y)\n",
        "            \n",
        "    print(f\"train_acc : {accuracy / len(train_ds)}, test_acc : {test_accuracy / len(test_ds)}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDVPz_AiRf2S",
        "outputId": "3ee8ff84-0297-4143-b5a0-f6cb731979cf"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model, os.path.join(SAVE_MODEL_PATH, \"Resnet18.pth\"))"
      ],
      "metadata": {
        "id": "rz39ddUZKFj1"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4o1wCb-DR-pQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}